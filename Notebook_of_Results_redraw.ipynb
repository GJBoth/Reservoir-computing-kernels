{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired from https://github.com/danieleds/Reservoir-Computing-in-PyTorch/blob/master/ESN/esn.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import seaborn\n",
    "import sys\n",
    "seaborn.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device\n",
    "#!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echo State Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implements an Echo State Network.\n",
    "    Parameters:\n",
    "      - input_size: size of the input\n",
    "      - reservoir_size: number of units in the reservoir\n",
    "      - scale_in: scaling of the input-to-reservoir matrix\n",
    "      - f: activation function for the state transition function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, reservoir_size, bias =0,\n",
    "                 scale_in=1.0, scale_res=1.0, f='erf', redraw=False):\n",
    "        super(ESN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.scale_in = scale_in\n",
    "        self.scale_res = scale_res\n",
    "        self.bias = bias\n",
    "        if f == 'erf':\n",
    "            self.f = torch.erf\n",
    "        if f == 'cos_rbf':\n",
    "            self.f = lambda x : np.sqrt(2)*torch.cos(x + self.bias).to(device)\n",
    "        if f == 'heaviside':\n",
    "            self.f = lambda x: 1 * (x > 0)\n",
    "        if f == 'sign':\n",
    "            self.f = torch.sign\n",
    "                \n",
    "        #self.f = f\n",
    "        \n",
    "        self.redraw = redraw\n",
    "        if self.redraw == False:\n",
    "            torch.manual_seed(1)\n",
    "            self.W_in = torch.randn(reservoir_size, input_size).to(device)\n",
    "            self.W_res = torch.randn(reservoir_size, reservoir_size).to(device)\n",
    "        \n",
    "    def forward(self, input_data, initial_state=None):\n",
    "        \"\"\"\n",
    "        Compute the reservoir states for the given sequence.\n",
    "        Parameters:\n",
    "          - input: Input sequence of shape (seq_len, input_size), i.e. (t,d)\n",
    "        \n",
    "        Returns: a tensor of shape (seq_len, reservoir_size)\n",
    "        \"\"\"\n",
    "        x = torch.zeros((input_data.shape[0], self.reservoir_size)).to(device)\n",
    "\n",
    "        if initial_state is not None:\n",
    "            x[0,:] = self.f( self.scale_in * torch.matmul(self.W_in, input_data[0,:]) +\n",
    "                            self.scale_res * torch.matmul(self.W_res, initial_state) ) / np.sqrt(self.reservoir_size)\n",
    "        else:\n",
    "            x[0,:] = self.f( self.scale_in * torch.matmul(self.W_in, input_data[0,:]) ) / np.sqrt(self.reservoir_size)\n",
    "        \n",
    "        # I made an important change here, i needs to start at 1 since the first step has been computed already\n",
    "        for i in range(1, input_data.shape[0]):\n",
    "            if self.redraw == True:\n",
    "                torch.manual_seed(i)\n",
    "                W_inn = self.scale_in*torch.randn((self.reservoir_size, self.input_size)).to(device)\n",
    "                W_in_times_i = self.scale_in * torch.matmul(W_inn, input_data[i,:])\n",
    "                del W_inn\n",
    "                W_ress = self.scale_res*torch.randn((self.reservoir_size, self.reservoir_size)).to(device)/np.sqrt(self.reservoir_size)\n",
    "                W_res_times_x = self.scale_res * torch.matmul(W_ress, x[i-1]) \n",
    "                del W_ress\n",
    "                x[i,:] = self.f( W_in_times_i + W_res_times_x ) / np.sqrt(self.reservoir_size)\n",
    "                del W_in_times_i, W_res_times_x\n",
    "            else:\n",
    "                x[i,:] = self.f( self.scale_in * torch.matmul(self.W_in, input_data[i,:]) + \n",
    "                                self.scale_res * torch.matmul(self.W_res, x[i-1]) ) / np.sqrt(self.reservoir_size)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_arcsin_kernel(input_data, initial_state,scale_res,scale_in = 1):\n",
    "    n_input = input_data.shape[0]\n",
    "    input_len = input_data.shape[1]\n",
    "    input_dim = input_data.shape[2]\n",
    "    n_res = initial_state.shape[0]\n",
    "    \n",
    "    K = torch.ones((n_input,n_input)).to(device) * torch.norm(initial_state)\n",
    "    for t in range(input_len):\n",
    "        current_input = input_data[:,t,:].reshape(n_input,input_dim)\n",
    "        input_gram = torch.matmul(current_input, current_input.t())\n",
    "        \n",
    "        diag_res = torch.diag(K)\n",
    "        diag_in = torch.diag(input_gram)\n",
    "        renorm_diag = 1 /(1+2*(scale_res**2)*diag_res +2*(scale_in)**2 *diag_in)\n",
    "        renorm_factor = torch.sqrt(torch.matmul(renorm_diag.reshape(n_input, 1), renorm_diag.reshape(1, n_input)))\n",
    "        K = torch.asin(2 * ((scale_res**2)*K + (scale_in**2) *input_gram) * renorm_factor) * 2 / np.pi\n",
    "    return K.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rbf_kernel(input_data, initial_state,scale_res,scale_in = 1):\n",
    "    n_input = input_data.shape[0]\n",
    "    input_len = input_data.shape[1]\n",
    "    input_dim = input_data.shape[2]\n",
    "    n_res = initial_state.shape[0]\n",
    "    \n",
    "    K = torch.ones((n_input,n_input)).to(device) * torch.norm(initial_state)\n",
    "    for t in range(input_len):\n",
    "        current_input = input_data[:,t,:].reshape(n_input,input_dim)\n",
    "        input_gram = torch.matmul(current_input, current_input.t())\n",
    "        \n",
    "        diag_res = torch.diag(K) #x**2\n",
    "        diag_in = torch.diag(input_gram) #i**2\n",
    "\n",
    "        K = torch.exp(-0.5*(diag_res.reshape(n_input,1))*scale_res**2)\\\n",
    "            *torch.exp(-0.5*(diag_res.reshape(1,n_input))*scale_res**2)\\\n",
    "                *torch.exp(K*scale_res**2)\\\n",
    "                    * torch.exp(- 0.5*torch.cdist(current_input,current_input)**2 *scale_in**2)\n",
    "    return K.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acos_heaviside_kernel(input_data, initial_state,scale_res,scale_in = 1):\n",
    "    n_input = input_data.shape[0]\n",
    "    input_len = input_data.shape[1]\n",
    "    input_dim = input_data.shape[2]\n",
    "    n_res = initial_state.shape[0]\n",
    "    \n",
    "    K = torch.ones((n_input,n_input)).to(device) * torch.norm(initial_state)\n",
    "    for t in range(input_len):\n",
    "        current_input = input_data[:,t,:].reshape(n_input,input_dim)\n",
    "        input_gram = torch.matmul(current_input, current_input.t())\n",
    "        \n",
    "        diag_res = torch.diag(K)\n",
    "        diag_in = torch.diag(input_gram)\n",
    "        renorm_diag = 1 /((scale_res**2)*diag_res + (scale_in)**2 * diag_in)\n",
    "        renorm_factor = torch.sqrt(torch.matmul(renorm_diag.reshape(n_input, 1), renorm_diag.reshape(1, n_input)))\n",
    "        K = 0.5 - torch.acos(((scale_res**2)*K + (scale_in**2) *input_gram) * renorm_factor) /(2*np.pi) \n",
    "    return K.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_asin_sign_kernel(input_data, initial_state,scale_res,scale_in = 1):\n",
    "    n_input = input_data.shape[0]\n",
    "    input_len = input_data.shape[1]\n",
    "    input_dim = input_data.shape[2]\n",
    "    n_res = initial_state.shape[0]\n",
    "    \n",
    "    K = torch.ones((n_input,n_input)).to(device) * torch.norm(initial_state)\n",
    "    for t in range(input_len):\n",
    "        current_input = input_data[:,t,:].reshape(n_input,input_dim)\n",
    "        input_gram = torch.matmul(current_input, current_input.t())\n",
    "        \n",
    "        diag_res = torch.diag(K)\n",
    "        diag_in = torch.diag(input_gram)\n",
    "        renorm_diag = 1 /((scale_res**2)*diag_res + (scale_in)**2 * diag_in)\n",
    "        renorm_factor = torch.sqrt(torch.matmul(renorm_diag.reshape(n_input, 1), renorm_diag.reshape(1, n_input)))\n",
    "        K = (2/np.pi)*torch.asin(((scale_res**2)*K + (scale_in**2) *input_gram) * renorm_factor)  \n",
    "    return K.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kuramoto-Sivashinsky equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KSequ.m - solution of Kuramoto-Sivashinsky equation\n",
    "# https://github.com/E-Renshaw/kuramoto-sivashinsky/blob/master/ksequ.py\n",
    "\n",
    "# u_t = -u*u_x - u_xx - u_xxxx, periodic boundary conditions on [0,32*pi]\n",
    "# computation is based on v = fft(u), so linear term is diagonal\n",
    "#\n",
    "# Using this program:\n",
    "# u is the initial condition / maybe add randomness\n",
    "# h is the time step\n",
    "# N is the number of points calculated along x = L de Wikipedia / N =100 le nb de points sur l'axe des x = input_dim\n",
    "# a is the max value in the initial condition\n",
    "# b is the min value in the initial condition\n",
    "# x is used when using a periodic boundary condition, to set up in terms of pi\n",
    "#\n",
    "# Initial condition and grid setup\n",
    "\n",
    "def kuramoto(N , tmax = 100): \n",
    "    N = N\n",
    "    x = np.transpose(np.conj(np.arange(1, N+1))) / N\n",
    "    a = -1\n",
    "    b = 1\n",
    "    #u = np.cos(x/16)*(1+np.sin(x/16)) # + add random phase in sinus between 0 and 2pi\n",
    "    #u = np.random.randn(1)\n",
    "    u = np.cos((1+np.random.uniform(0,1))*x/16+np.random.uniform(0,2*np.pi))#*(1+np.sin(1+np.random.uniform(0,1)*x/16+np.random.uniform(0,2*np.pi)))\n",
    "    v = np.fft.fft(u)\n",
    "# scalars for ETDRK4\n",
    "    h = 1#0.25 time step\n",
    "    k = np.transpose(np.conj(np.concatenate((np.arange(0, N/2), np.array([0]), np.arange(-N/2+1, 0))))) / 16\n",
    "    L = k**2 - k**4\n",
    "    E = np.exp(h*L)\n",
    "    E_2 = np.exp(h*L/2)\n",
    "    M = 16\n",
    "    r = np.exp(1j*np.pi*(np.arange(1, M+1)-0.5) / M)\n",
    "    LR = h*np.transpose(np.repeat([L], M, axis=0)) + np.repeat([r], N, axis=0)\n",
    "    Q = h*np.real(np.mean((np.exp(LR/2)-1)/LR, axis=1))\n",
    "    f1 = h*np.real(np.mean((-4-LR+np.exp(LR)*(4-3*LR+LR**2))/LR**3, axis=1))\n",
    "    f2 = h*np.real(np.mean((2+LR+np.exp(LR)*(-2+LR))/LR**3, axis=1))\n",
    "    f3 = h*np.real(np.mean((-4-3*LR-LR**2+np.exp(LR)*(4-LR))/LR**3, axis=1))\n",
    "# main loop\n",
    "    uu = np.array([u])\n",
    "    tt = 0\n",
    "    tmax = tmax#150\n",
    "    nmax = round(tmax/h)\n",
    "    nplt = int((tmax/100)/h)\n",
    "    g = -0.5j*k\n",
    "    for n in range(1,nmax):\n",
    "        t = n*h\n",
    "        Nv = g*np.fft.fft(np.real(np.fft.ifft(v))**2)\n",
    "        a = E_2*v + Q*Nv\n",
    "        Na = g*np.fft.fft(np.real(np.fft.ifft(a))**2)\n",
    "        b = E_2*v + Q*Na\n",
    "        Nb = g*np.fft.fft(np.real(np.fft.ifft(b))**2)\n",
    "        c = E_2*a + Q*(2*Nb-Nv)\n",
    "        Nc = g*np.fft.fft(np.real(np.fft.ifft(c))**2)\n",
    "        v = E*v + Nv*f1 + 2*(Na+Nb)*f2 + Nc*f3\n",
    "        #if n%nplt == 0:\n",
    "        u = np.real(np.fft.ifft(v))\n",
    "        uu = np.append(uu, np.array([u]), axis=0)\n",
    "        tt = np.hstack((tt, t))\n",
    "    return uu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of normalized random gaussian data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_data(n_input, input_len_max, input_dim,fix_seed= False):\n",
    "    if fix_seed == True:\n",
    "        torch.manual_seed(42)\n",
    "    return torch.randn(n_input, input_len_max, input_dim).to(device) / np.sqrt(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check to compare the Kernel Matrix and the Gram Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcsin kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_data = gaussian_data(n_input, input_len, input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=2000)\n",
    "error_gauss_asin = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_arcsin_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in,f='erf',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_gauss_asin[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))\n",
    "    del X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_gauss_asin.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbf kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 0.01 # variance of reservoir\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_data = gaussian_data(n_input, input_len, input_dim)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=2000)\n",
    "error_gauss_rbf = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_rbf_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    \n",
    "    torch.manual_seed(i)\n",
    "    bias = torch.Tensor(np.random.uniform(0,2*np.pi, size=n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, bias = bias, scale_res = scale_res,\\\n",
    "                    scale_in = scale_in, \\\n",
    "                    f='cos_rbf',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_gauss_rbf[i] = loss(K_hat,K)/ loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_gauss_rbf.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcos_heaviside kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_data = gaussian_data(n_input, input_len, input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=2000)\n",
    "error_gauss_acos_heaviside = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_acos_heaviside_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in, f='heaviside',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_gauss_acos_heaviside[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_gauss_acos_heaviside.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asin_sign kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_data = gaussian_data(n_input, input_len, input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=2000)\n",
    "error_gauss_asin_sign = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_asin_sign_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in, f='sign',,redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_gauss_asin_sign[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_gauss_asin_sign.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcsin kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "input_data = torch.zeros(n_input, input_len, input_dim).to(device)\n",
    "for n_inp in range(n_input):\n",
    "    input_data[n_inp,:,:] = torch.Tensor(kuramoto(input_dim, input_len))/np.sqrt(input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=2000)\n",
    "error_kura_asin = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_arcsin_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in,f='erf',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_kura_asin[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_kura_asin.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbf kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "input_data = torch.zeros(n_input, input_len, input_dim).to(device)\n",
    "for n_inp in range(n_input):\n",
    "    input_data[n_inp,:,:] = torch.Tensor(kuramoto(input_dim, input_len))/np.sqrt(input_dim)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=1000)\n",
    "error_kura_rbf = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_rbf_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    torch.manual_seed(i)\n",
    "    bias = torch.Tensor(np.random.uniform(0,2*np.pi, size=n_res)).to(device)\n",
    "    \n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, bias = bias,scale_res = scale_res,\\\n",
    "                    scale_in = scale_in, \\\n",
    "                    f='cos_rbf',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_kura_rbf[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_kura_rbf.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heaviside\n",
    "#arcsin kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "input_data = torch.zeros(n_input, input_len, input_dim).to(device)\n",
    "for n_inp in range(n_input):\n",
    "    input_data[n_inp,:,:] = torch.Tensor(kuramoto(input_dim, input_len))/np.sqrt(input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=1000)\n",
    "error_kura_acos_heaviside = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_acos_heaviside_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in,f='heaviside',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_kura_acos_heaviside[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_kura_acos_heaviside.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asin_sign kernel\n",
    "\n",
    "n_input = 50 # number of time series\n",
    "input_len = 40 # time steps t\n",
    "input_dim = 100 #dimension of the time series\n",
    "scale_in = 1  # variance of input\n",
    "scale_res = 1 # variance of reservoir\n",
    "\n",
    "input_data = torch.zeros(n_input, input_len, input_dim).to(device)\n",
    "for n_inp in range(n_input):\n",
    "    input_data[n_inp,:,:] = torch.Tensor(kuramoto(input_dim, input_len))/np.sqrt(input_dim)\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "n_res_range = np.arange(start=100,stop=10000, step=1000)\n",
    "error_kura_asin_sign = torch.zeros(len(n_res_range))\n",
    "\n",
    "for i, n_res in tqdm(enumerate(n_res_range)):\n",
    "    initial_state = torch.randn(n_res).to(device) / np.sqrt(n_res)\n",
    "    K = compute_asin_sign_kernel(input_data, initial_state, scale_res)\n",
    "    X_final = torch.zeros((n_input,n_res)).to(device)\n",
    "    for n_in in range(n_input):\n",
    "        model = ESN(input_dim, reservoir_size=n_res, scale_res = scale_res, scale_in = scale_in, f='sign',redraw=True)\n",
    "        X = model.forward(input_data[n_in,:,:].reshape(input_len,input_dim), initial_state = initial_state).to(device)\n",
    "        X_final[n_in,:] = X[-1,:]\n",
    "    \n",
    "    K_hat = torch.matmul(X_final,X_final.t())\n",
    "    error_kura_asin_sign[i] = loss(K_hat,K) / loss(K, torch.zeros(n_input, n_input).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(n_res_range, error_kura_asin_sign.numpy())\n",
    "plt.title('Error vs size of reservoir');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "_, axes  = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plot = axes[0].imshow(K.cpu().numpy())\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].set_title(\"Explicit kernel Gram matrix\")\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[1].imshow(K_hat.cpu().numpy())\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].set_title(\"Reservoir Gram matrix\")\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax)\n",
    "\n",
    "plot = axes[2].imshow((K-K_hat).cpu().numpy())\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].set_title(\"Difference\")\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(plot, cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
