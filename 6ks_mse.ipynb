{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set()\n",
    "\n",
    "import reservoir\n",
    "import reckernel\n",
    "import kuramoto\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "today = '200609'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE for time series prediction\n",
    "\n",
    "We repeat it several times to obtain the average on several random realizations.\n",
    "\n",
    "## Reservoir Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:30<00:00, 15.01s/it]\n"
     ]
    }
   ],
   "source": [
    "N_seed = 10\n",
    "\n",
    "L = 22 / (2 * np.pi)  # length\n",
    "N = 100  # space discretization step\n",
    "dt = 0.25  # time discretization step\n",
    "N_train = 70000\n",
    "N_test = 5000\n",
    "N_init = 1000  # remove the initial points\n",
    "tend = (N_train + N_test) * dt + N_init\n",
    "\n",
    "n_rec = 600\n",
    "test_len = 2000\n",
    "rc_mse = torch.zeros(test_len, n_rec+1, N_seed)\n",
    "\n",
    "for seed in tqdm(range(N_seed)):\n",
    "    np.random.seed(seed)\n",
    "    dns = kuramoto.KS(L=L, N=N, dt=dt, tend=tend)\n",
    "    dns.simulate()\n",
    "    u = dns.uu[N_init:] / np.sqrt(N)\n",
    "    [u_train, u_test, _] = np.split(u, [N_train, N_train+N_test], axis=0)\n",
    "    u_train_t = torch.from_numpy(u_train).to(device)\n",
    "    u_test_t = torch.from_numpy(u_test).to(device)\n",
    "    input_len, input_dim = u_train_t.shape\n",
    "    \n",
    "    # RC parameters\n",
    "    n_res = 1024-input_dim\n",
    "    input_scale = 0.4\n",
    "    res_scale = 0.9\n",
    "    bias_scale = 0.4\n",
    "    renorm_factor = 1.1 * np.sqrt(input_dim / n_res)\n",
    "    alpha = 1e-2\n",
    "    leak_rate = 1\n",
    "\n",
    "    # Generation of train data\n",
    "    pred_horizon_range = 1\n",
    "    out_train = torch.zeros(input_len, input_dim * pred_horizon_range).to(device)\n",
    "    for pred_horizon in range(1, pred_horizon_range+1):\n",
    "        out_train[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(u_train_t, -pred_horizon, dims=0)\n",
    "\n",
    "#     print(\"Training forward\")\n",
    "    torch.manual_seed(seed)\n",
    "    bias = bias_scale * torch.randn(n_res).to(device)\n",
    "    model = reservoir.ESN(input_dim, res_size=n_res, res_scale=res_scale, input_scale=input_scale, \n",
    "                          f='erf', leak_rate=leak_rate, bias=bias, random_projection='gaussian', seed=seed)\n",
    "    X = model.forward(u_train_t).to(device)\n",
    "    X = torch.cat((X, u_train_t*renorm_factor), dim=1)\n",
    "#     print(\"Training weights\")\n",
    "    output_w = model.train(X, out_train, alpha=alpha)\n",
    "    \n",
    "#     print(\"Testing forward\")\n",
    "    test_len = 2000\n",
    "    Xtest = model.forward(u_test_t[:test_len]).to(device)\n",
    "\n",
    "#     print(\"Testing recursive prediction\")\n",
    "    n_rec = 600\n",
    "    rec_pred_data = model.rec_pred(Xtest, output_w, n_rec, input_dim, concat=u_test_t[:test_len]*renorm_factor, renorm_factor=renorm_factor)\n",
    "\n",
    "    new_pred_horizon = pred_horizon_range * (n_rec+1)\n",
    "    out_test = torch.zeros(N_test, input_dim * new_pred_horizon).to(device)\n",
    "    for pred_horizon in range(1, new_pred_horizon+1):\n",
    "        out_test[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(u_test_t, -pred_horizon, dims=0)\n",
    "    out_test = out_test[:test_len, :]\n",
    "    truth = out_test[:test_len, :].reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    rec_pred = rec_pred_data.reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    diff = rec_pred - truth.cpu()\n",
    "    rc_mse[:, :, seed] = torch.mean(diff**2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out/' + today + '_ks_rc_mse_nres' + str(n_res), rc_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Reservoir Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:12<00:00, 19.29s/it]\n"
     ]
    }
   ],
   "source": [
    "N_seed = 10\n",
    "\n",
    "L = 22 / (2 * np.pi)  # length\n",
    "N = 100  # space discretization step\n",
    "dt = 0.25  # time discretization step\n",
    "N_train = 70000\n",
    "N_test = 5000\n",
    "N_init = 1000  # remove the initial points\n",
    "tend = (N_train + N_test) * dt + N_init\n",
    "\n",
    "n_rec = 600\n",
    "test_len = 2000\n",
    "src_mse = torch.zeros(test_len, n_rec+1, N_seed)\n",
    "\n",
    "for seed in tqdm(range(N_seed)):\n",
    "    np.random.seed(seed)\n",
    "    dns = kuramoto.KS(L=L, N=N, dt=dt, tend=tend)\n",
    "    dns.simulate()\n",
    "    u = dns.uu[N_init:] / np.sqrt(N)\n",
    "    [u_train, u_test, _] = np.split(u, [N_train, N_train+N_test], axis=0)\n",
    "    u_train_t = torch.from_numpy(u_train).to(device)\n",
    "    u_test_t = torch.from_numpy(u_test).to(device)\n",
    "    input_len, input_dim = u_train_t.shape\n",
    "    \n",
    "    # RC parameters\n",
    "    n_res = 1024-input_dim\n",
    "    input_scale = 0.4\n",
    "    res_scale = 0.9\n",
    "    bias_scale = 0.4\n",
    "    renorm_factor = 1.1 * np.sqrt(input_dim / n_res)\n",
    "    alpha = 1e-2\n",
    "    leak_rate = 1\n",
    "\n",
    "    # Generation of train data\n",
    "    pred_horizon_range = 1\n",
    "    out_train = torch.zeros(input_len, input_dim * pred_horizon_range).to(device)\n",
    "    for pred_horizon in range(1, pred_horizon_range+1):\n",
    "        out_train[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(u_train_t, -pred_horizon, dims=0)\n",
    "\n",
    "#     print(\"Training forward\")\n",
    "    torch.manual_seed(seed)\n",
    "    bias = bias_scale * torch.randn(n_res).to(device)\n",
    "    model = reservoir.ESN(input_dim, res_size=n_res, res_scale=res_scale, input_scale=input_scale, \n",
    "                          f='erf', leak_rate=leak_rate, bias=bias, random_projection='structured', seed=seed)\n",
    "    X = model.forward(u_train_t).to(device)\n",
    "    X = torch.cat((X, u_train_t*renorm_factor), dim=1)\n",
    "#     print(\"Training weights\")\n",
    "    output_w = model.train(X, out_train, alpha=alpha)\n",
    "    \n",
    "#     print(\"Testing forward\")\n",
    "    test_len = 2000\n",
    "    Xtest = model.forward(u_test_t[:test_len]).to(device)\n",
    "\n",
    "#     print(\"Testing recursive prediction\")\n",
    "    n_rec = 600\n",
    "    rec_pred_data = model.rec_pred(Xtest, output_w, n_rec, input_dim, concat=u_test_t[:test_len]*renorm_factor, renorm_factor=renorm_factor)\n",
    "\n",
    "    new_pred_horizon = pred_horizon_range * (n_rec+1)\n",
    "    out_test = torch.zeros(N_test, input_dim * new_pred_horizon).to(device)\n",
    "    for pred_horizon in range(1, new_pred_horizon+1):\n",
    "        out_test[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(u_test_t, -pred_horizon, dims=0)\n",
    "    out_test = out_test[:test_len, :]\n",
    "    truth = out_test[:test_len, :].reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    rec_pred = rec_pred_data.reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    diff = rec_pred - truth.cpu()\n",
    "    src_mse[:, :, seed] = torch.mean(diff**2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out/' + today + '_ks_src_mse_nres' + str(n_res), src_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:13:23<00:00, 440.32s/it]\n"
     ]
    }
   ],
   "source": [
    "N_seed = 10\n",
    "\n",
    "L = 22 / (2 * np.pi)  # length\n",
    "N = 100  # space discretization step\n",
    "dt = 0.25  # time discretization step\n",
    "N_train = 70000\n",
    "N_test = 5000\n",
    "N_init = 1000  # remove the initial points\n",
    "tend = (N_train + N_test) * dt + N_init\n",
    "\n",
    "n_rec = 600\n",
    "test_len = 2000\n",
    "rk_mse = torch.zeros(test_len, n_rec+1, N_seed)\n",
    "\n",
    "for seed in tqdm(range(N_seed)):\n",
    "    np.random.seed(seed)\n",
    "    dns = kuramoto.KS(L=L, N=N, dt=dt, tend=tend)\n",
    "    dns.simulate()\n",
    "    u = dns.uu[N_init:] / np.sqrt(N)\n",
    "    [u_train, u_test, _] = np.split(u, [N_train, N_train+N_test], axis=0)\n",
    "    u_train_t = torch.from_numpy(u_train).to(device)\n",
    "    u_test_t = torch.from_numpy(u_test).to(device)\n",
    "    input_len, input_dim = u_train_t.shape\n",
    "    \n",
    "    # RK parameters\n",
    "    input_scale = 0.4\n",
    "    res_scale = 0.9\n",
    "    bias_scale = 0.4\n",
    "    renorm_factor = 1.1\n",
    "    alpha = 3e-3\n",
    "    n_iter = 50\n",
    "\n",
    "#     print(\"Training forward\")\n",
    "    model = reckernel.RecKernel(function='arcsin', res_scale=res_scale, input_scale=input_scale, n_iter=n_iter,\n",
    "                               bias_scale=bias_scale, memory_efficient=False)\n",
    "\n",
    "    step = 10\n",
    "    in_len = (input_len - n_iter) // step\n",
    "    concat_train = torch.zeros(in_len, n_iter, input_dim).to(device)\n",
    "    for i in range(n_iter):\n",
    "        concat_train[:, i, :] = u_train_t[i:i+step*in_len:step, :]\n",
    "    K = model.forward(concat_train).to(device)\n",
    "\n",
    "    final_train = concat_train[:, -1, :].reshape(in_len, input_dim)\n",
    "    final_input_gram = final_train @ final_train.T\n",
    "    K += renorm_factor * final_input_gram\n",
    "\n",
    "#     print(\"Training weights\")\n",
    "    pred_horizon_range = 1\n",
    "    out_train = torch.zeros(in_len, input_dim * pred_horizon_range).to(device)\n",
    "    for pred_horizon in range(1, pred_horizon_range+1):\n",
    "        out_train[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(\n",
    "            u_train_t, -pred_horizon, dims=0)[n_iter-1:n_iter-1+step*in_len:step, :]\n",
    "\n",
    "    output_w = model.train(K, out_train, alpha=alpha)\n",
    "\n",
    "#     print(\"Testing forward\")\n",
    "    test_len = 2000\n",
    "    concat_test = torch.zeros(test_len, n_iter, input_dim).to(device)\n",
    "    for i in range(n_iter):\n",
    "        concat_test[:, i, :] = u_test_t[i:i+test_len, :]\n",
    "    Ktest, diag_res_train, diag_res_test = model.forward_test(concat_train, concat_test, bypass=True)\n",
    "\n",
    "#     print(\"Testing recursive prediction\")\n",
    "    n_rec = 600\n",
    "    rec_pred_data = model.rec_pred_concat(Ktest, concat_train, concat_test, output_w, n_rec,\n",
    "                                          diag_res_train, diag_res_test, renorm_factor)\n",
    "    \n",
    "    new_pred_horizon = pred_horizon_range * (n_rec+1)\n",
    "    out_test = torch.zeros(test_len, input_dim * new_pred_horizon).to(device)\n",
    "    for pred_horizon in range(1, new_pred_horizon+1):\n",
    "        out_test[:, (pred_horizon-1)*input_dim:pred_horizon*input_dim] = torch.roll(u_test_t[n_iter:n_iter+test_len, :], -pred_horizon, dims=0)\n",
    "    out_test = out_test[:test_len, :]\n",
    "    truth = out_test[:test_len, :].reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    rec_pred = rec_pred_data.reshape(test_len, (n_rec+1)*pred_horizon_range, input_dim)\n",
    "\n",
    "    diff = rec_pred - truth.cpu()\n",
    "    rk_mse[:, :, seed] = torch.mean(diff**2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('out/' + today + '_ks_src_mse_nres' + str(n_res), rk_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
